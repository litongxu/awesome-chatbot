{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6uNrFWq5BRba"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Copyright 2018 Google LLC.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Your Own Visualizations!\n",
    "Instructions:\n",
    "1. Install tensor2tensor and train up a Transformer model following the instruction in the repository https://github.com/tensorflow/tensor2tensor.\n",
    "2. Update cell 3 to point to your checkpoint, it is currently set up to read from the default checkpoint location that would be created from following the instructions above.\n",
    "3. If you used custom hyper parameters then update cell 4.\n",
    "4. Run the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0216 08:37:38.791485 140435951621952 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0216 08:37:39.485625 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0216 08:37:40.594677 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/tensor2tensor/rl/gym_utils.py:219: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0216 08:37:40.601079 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0216 08:37:40.602132 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0216 08:37:40.614391 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
      "\n",
      "W0216 08:37:40.615057 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "W0216 08:37:40.648072 140435951621952 deprecation_wrapper.py:119] From /home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/trainer_lib.py:109: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.bin import t2t_decoder  # To register the hparams set\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.visualization import attention\n",
    "from tensor2tensor.visualization import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
       "  }\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT THE MODEL YOU WANT TO LOAD HERE!\n",
    "CHECKPOINT = os.path.expanduser('~/workspace/awesome-chatbot/saved/t2t_train/chat_movie_30_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HParams\n",
    "problem_name = 'chat_line_problem'\n",
    "#problem_name = 'chat'\n",
    "data_dir = os.path.expanduser('~/workspace/awesome-chatbot/data/t2t_data/chat_movie_30_8')\n",
    "model_name = \"transformer\"\n",
    "hparams_set = \"transformer_chat\"\n",
    "#hparams_set = 'chat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_chat transformer True True\n"
     ]
    }
   ],
   "source": [
    "print(hparams_set, model_name, os.path.isdir(data_dir), os.path.isdir(CHECKPOINT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'transformer_chat never registered with registry hparams. Available:\\n     adaptive:\\n      * adaptive_universal_transformer_base\\n      * adaptive_universal_transformer_base_dropout03\\n      * adaptive_universal_transformer_base_dropout05\\n      * adaptive_universal_transformer_base_tpu\\n      * adaptive_universal_transformer_concat_tiny\\n      * adaptive_universal_transformer_global_base\\n      * adaptive_universal_transformer_global_base_tpu\\n      * adaptive_universal_transformer_mix_after_ut_base\\n      * adaptive_universal_transformer_mix_before_ut_base\\n      * adaptive_universal_transformer_multilayer_hard\\n      * adaptive_universal_transformer_multilayer_tpu\\n      * adaptive_universal_transformer_position_random_timing_tiny\\n      * adaptive_universal_transformer_small\\n      * adaptive_universal_transformer_tall\\n      * adaptive_universal_transformer_tall_actlossw0\\n      * adaptive_universal_transformer_tall_actlossw001\\n      * adaptive_universal_transformer_tiny\\n      * adaptive_universal_transformer_with_sru_base\\n    afx:\\n      * afx_adafactor\\n      * afx_adam\\n      * afx_base\\n      * afx_clip\\n      * afx_clip2\\n      * afx_clip_factored\\n      * afx_factored\\n      * afx_fast\\n      * afx_mimic_adam\\n      * afx_pow05\\n      * afx_pow08\\n      * afx_pow08_clip\\n      * afx_pow10\\n      * afx_relative\\n      * afx_small\\n      * afx_small_bfloat16\\n      * afx_small_p10\\n      * afx_small_p11\\n      * afx_small_p12\\n      * afx_small_p16\\n      * afx_small_p8\\n      * afx_unscale\\n      * afx_unscale_relative\\n    aligned:\\n      * aligned_8k\\n      * aligned_8k_grouped\\n      * aligned_base\\n      * aligned_grouped\\n      * aligned_local\\n      * aligned_local_1k\\n      * aligned_local_expert\\n      * aligned_lsh\\n      * aligned_memory_efficient\\n      * aligned_moe\\n      * aligned_no_att\\n      * aligned_no_timing\\n      * aligned_pos_emb\\n      * aligned_pseudolocal\\n      * aligned_pseudolocal_256\\n    attention:\\n      * attention_lm_11k\\n      * attention_lm_12k\\n      * attention_lm_16k\\n      * attention_lm_ae_extended\\n      * attention_lm_attention_moe_tiny\\n      * attention_lm_base\\n      * attention_lm_hybrid_v2\\n      * attention_lm_moe_24b_diet\\n      * attention_lm_moe_32b_diet\\n      * attention_lm_moe_base\\n      * attention_lm_moe_base_ae\\n      * attention_lm_moe_base_hybrid\\n      * attention_lm_moe_base_local\\n      * attention_lm_moe_base_long_seq\\n      * attention_lm_moe_base_memeff\\n      * attention_lm_moe_large\\n      * attention_lm_moe_large_diet\\n      * attention_lm_moe_memory_efficient\\n      * attention_lm_moe_small\\n      * attention_lm_moe_tiny\\n      * attention_lm_moe_translation\\n      * attention_lm_moe_unscramble_base\\n      * attention_lm_no_moe_small\\n      * attention_lm_small\\n      * attention_lm_translation\\n      * attention_lm_translation_full_attention\\n      * attention_lm_translation_l12\\n    autoencoder:\\n      * autoencoder_autoregressive\\n      * autoencoder_basic\\n      * autoencoder_basic_discrete\\n      * autoencoder_discrete_cifar\\n      * autoencoder_discrete_pong\\n      * autoencoder_discrete_tiny\\n      * autoencoder_ordered_discrete\\n      * autoencoder_ordered_discrete_hs256\\n      * autoencoder_ordered_discrete_image64\\n      * autoencoder_ordered_discrete_patched\\n      * autoencoder_ordered_discrete_single\\n      * autoencoder_ordered_discrete_vq\\n      * autoencoder_ordered_text\\n      * autoencoder_ordered_text_small\\n      * autoencoder_residual\\n      * autoencoder_residual_discrete\\n      * autoencoder_residual_discrete_big\\n      * autoencoder_residual_text\\n      * autoencoder_stacked\\n    basic:\\n      * basic_1\\n      * basic_fc_small\\n      * basic_policy_parameters\\n    bytenet:\\n      * bytenet_base\\n    cycle:\\n      * cycle_gan_small\\n    denoise:\\n      * denoise_dense_2_m30\\n      * denoise_m15\\n      * denoise_m30\\n      * denoise_t15\\n      * denoise_v1_m15\\n      * denoise_v1_m30\\n      * denoise_v1_m50\\n      * denoise_v1_t15\\n      * denoise_v1_z15\\n      * denoise_z15\\n    discrete:\\n      * discrete_random_action_base\\n    distill:\\n      * distill_resnet_32_to_15_cifar20x5\\n    dqn:\\n      * dqn_atari_base\\n      * dqn_original_params\\n    evolved:\\n      * evolved_transformer_base\\n      * evolved_transformer_base_tpu\\n      * evolved_transformer_big\\n      * evolved_transformer_big_tpu\\n    frame:\\n      * frame_glow_hparams\\n    gene:\\n      * gene_expression_conv_base\\n    glow:\\n      * glow_hparams\\n    image:\\n      * image_transformer2d_base\\n      * image_transformer_base\\n    imagetransformer1d:\\n      * imagetransformer1d_base_12l_64by64\\n      * imagetransformer1d_base_8l_64by64\\n    imagetransformer2d:\\n      * imagetransformer2d_base\\n      * imagetransformer2d_base_12l_8_16_big\\n      * imagetransformer2d_base_12l_8_64_64by64\\n      * imagetransformer2d_base_14l_8_16_big\\n      * imagetransformer2d_base_14l_8_16_big_uncond\\n      * imagetransformer2d_base_8l_8_16\\n      * imagetransformer2d_base_8l_8_16_big\\n      * imagetransformer2d_base_8l_8_16_big_16k\\n      * imagetransformer2d_base_8l_8_16_ls\\n      * imagetransformer2d_base_8l_8_32_big\\n      * imagetransformer2d_base_8l_8_64_64by64\\n      * imagetransformer2d_tiny\\n    imagetransformer:\\n      * imagetransformer_ae_cifar\\n      * imagetransformer_b10l_4h_big_uncond_dr01_tpu\\n      * imagetransformer_b10l_4h_big_uncond_dr03_lr025_tpu\\n      * imagetransformer_b10l_4h_big_uncond_dr03_tpu\\n      * imagetransformer_b10l_dr03_moe_tpu\\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr01_im\\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_b128_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_b256_uncond_dr03_rel_tpu\\n      * imagetransformer_b12l_4h_b256_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_big_uncond_dr03_lr025_tpu\\n      * imagetransformer_b12l_4h_big_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_uncond_dr03_tpu\\n      * imagetransformer_b12l_8h_b256_uncond_dr03_tpu\\n      * imagetransformer_bas8l_8h_big_uncond_dr03_imgnet\\n      * imagetransformer_base\\n      * imagetransformer_base_10l_16h_big_dr01_imgnet\\n      * imagetransformer_base_10l_16h_big_dr01_moe_imgnet\\n      * imagetransformer_base_10l_16h_big_uncond_dr01_imgnet\\n      * imagetransformer_base_10l_8h_big_cond_dr03_dan\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64_2d\\n      * imagetransformer_base_12l_8h_big\\n      * imagetransformer_base_12l_8h_big_uncond\\n      * imagetransformer_base_14l_8h_big\\n      * imagetransformer_base_14l_8h_big_dr01\\n      * imagetransformer_base_14l_8h_big_uncond\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_128\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_b\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_c\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_d\\n      * imagetransformer_base_imagenet_tpu\\n      * imagetransformer_base_rel\\n      * imagetransformer_base_tpu\\n      * imagetransformer_cifar10_base\\n      * imagetransformer_cifar10_base_dmol\\n      * imagetransformer_imagenet32_base\\n      * imagetransformer_moe_tiny\\n      * imagetransformer_sep_channels\\n      * imagetransformer_sep_channels_12l_16h_imagenet_large\\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc\\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc_128\\n      * imagetransformer_sep_channels_8l\\n      * imagetransformer_sep_channels_8l_8h\\n      * imagetransformer_sep_channels_8l_8h_local_and_global_att\\n      * imagetransformer_sep_channels_8l_multipos3\\n      * imagetransformer_sep_channels_8l_tpu\\n      * imagetransformer_sep_output_channels_8l_local_and_global_att\\n      * imagetransformer_tiny\\n      * imagetransformer_tiny_tpu\\n    imagetransformerpp:\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_a\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_b\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_g\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_k\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_l\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_bs1\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_rel\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_relsh\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_eval\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p_bs1\\n      * imagetransformerpp_base_5l_8h_big_uncond_dr00_dan_g_bs1\\n      * imagetransformerpp_base_5l_8h_dr00_dan_g_bs1_adafactor\\n      * imagetransformerpp_base_6l_8h_dr00_dan_g_bs1_adafactor\\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan\\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan_a\\n      * imagetransformerpp_sep_channels_8l_8h\\n      * imagetransformerpp_tiny\\n    img2img:\\n      * img2img_transformer2d_base\\n      * img2img_transformer2d_n103\\n      * img2img_transformer2d_n24\\n      * img2img_transformer2d_n3\\n      * img2img_transformer2d_n31\\n      * img2img_transformer2d_n44\\n      * img2img_transformer2d_q1\\n      * img2img_transformer2d_q2\\n      * img2img_transformer2d_q3\\n      * img2img_transformer2d_tiny\\n      * img2img_transformer_b1\\n      * img2img_transformer_b2\\n      * img2img_transformer_b3\\n      * img2img_transformer_b3_bs1\\n      * img2img_transformer_b3_bs10\\n      * img2img_transformer_b3_bs2\\n      * img2img_transformer_b3_bs3\\n      * img2img_transformer_b3_bs4\\n      * img2img_transformer_b3_bs5\\n      * img2img_transformer_b3_bs6\\n      * img2img_transformer_b3_bs7\\n      * img2img_transformer_b3_bs8\\n      * img2img_transformer_b3_bs9\\n      * img2img_transformer_base\\n      * img2img_transformer_base_tpu\\n      * img2img_transformer_dilated\\n      * img2img_transformer_tiny\\n      * img2img_transformer_tiny_tpu\\n    lmx:\\n      * lmx_base\\n      * lmx_h1k_f4k\\n      * lmx_h1k_f64k\\n      * lmx_h2k_f8k\\n      * lmx_h3k_f12k\\n      * lmx_h4k_f16k\\n      * lmx_moe\\n      * lmx_moe_h1k_f4k_x32\\n      * lmx_moe_h1k_f8k_x16\\n      * lmx_relative\\n      * lmx_relative_nopos\\n    lstm:\\n      * lstm_area_attention_base\\n      * lstm_area_attention_char\\n      * lstm_area_attention_char_enfr\\n      * lstm_area_attention_enfr\\n      * lstm_asr_v1\\n      * lstm_attention\\n      * lstm_bahdanau_attention\\n      * lstm_bahdanau_attention_multi\\n      * lstm_luong_attention\\n      * lstm_luong_attention_multi\\n      * lstm_seq2seq\\n    mqp:\\n      * mqp_ende_base\\n      * mqp_ende_h1_ff6784\\n      * mqp_ende_h1_kv1024\\n      * mqp_ende_h2_ff6400\\n      * mqp_ende_h2_kv512\\n      * mqp_ende_h2_kv64_ff6784\\n      * mqp_ende_h4_ff5632\\n      * mqp_ende_h4_kv256\\n      * mqp_ende_h4_kv32_ff6784\\n      * mqp_ende_h8_kv16_ff6784\\n      * mqp_ende_local\\n      * mqp_ende_mq8\\n      * mqp_ende_mq8_ff5440\\n      * mqp_ende_mq8_ff5440_local\\n      * mqp_lm1b_base\\n      * mqp_lm1b_h1_ff9984\\n      * mqp_lm1b_h2_kv64_ff9984\\n      * mqp_lm1b_h4_kv32_ff9984\\n      * mqp_lm1b_h8_kv16_ff9984\\n      * mqp_lm1b_mq8\\n      * mqp_lm1b_mq8_ff9088\\n    mtf:\\n      * mtf_bitransformer_all_layers_tiny\\n      * mtf_bitransformer_base\\n      * mtf_bitransformer_tiny\\n      * mtf_image_transformer_base\\n      * mtf_image_transformer_base_cifar\\n      * mtf_image_transformer_base_imagenet\\n      * mtf_image_transformer_base_imagenet_mp\\n      * mtf_image_transformer_base_imagenet_mp128\\n      * mtf_image_transformer_base_imagenet_mp64\\n      * mtf_image_transformer_base_imagenet_mp_sp\\n      * mtf_image_transformer_base_single\\n      * mtf_image_transformer_cifar_4x\\n      * mtf_image_transformer_cifar_mp_4x\\n      * mtf_image_transformer_length_sharded\\n      * mtf_image_transformer_single\\n      * mtf_image_transformer_tiny\\n      * mtf_image_transformer_tiny_8gpu\\n      * mtf_image_transformer_tiny_spatial1d\\n      * mtf_image_transformer_tiny_spatial2d\\n      * mtf_resnet_base\\n      * mtf_resnet_base_cifar\\n      * mtf_resnet_base_single\\n      * mtf_resnet_single\\n      * mtf_resnet_tiny\\n      * mtf_transformer_base\\n      * mtf_transformer_base_lm\\n      * mtf_transformer_enc_single\\n      * mtf_transformer_lm_baseline\\n      * mtf_transformer_paper_lm_0\\n      * mtf_transformer_paper_lm_1\\n      * mtf_transformer_paper_lm_2\\n      * mtf_transformer_paper_lm_3\\n      * mtf_transformer_paper_lm_4\\n      * mtf_transformer_paper_lm_5\\n      * mtf_transformer_paper_lm_m1\\n      * mtf_transformer_paper_tr_0\\n      * mtf_transformer_paper_tr_0_a32\\n      * mtf_transformer_paper_tr_0_mesh_128\\n      * mtf_transformer_paper_tr_0_mesh_512\\n      * mtf_transformer_paper_tr_0_mesh_8\\n      * mtf_transformer_paper_tr_0_mesh_8_v2\\n      * mtf_transformer_paper_tr_0_nf\\n      * mtf_transformer_paper_tr_1\\n      * mtf_transformer_paper_tr_2\\n      * mtf_transformer_paper_tr_3\\n      * mtf_transformer_paper_tr_4\\n      * mtf_transformer_paper_tr_4_mesh_16_8\\n      * mtf_transformer_paper_tr_6_mesh_64_8\\n      * mtf_transformer_paper_tr_m1\\n      * mtf_transformer_single\\n      * mtf_transformer_tiny\\n      * mtf_transformer_tiny_8gpu\\n      * mtf_transformer_tiny_denoising\\n      * mtf_transformer_tiny_lm\\n      * mtf_unitransformer_all_layers_tiny\\n      * mtf_unitransformer_base\\n      * mtf_unitransformer_tiny\\n    mtr:\\n      * mtr_lm_dense\\n      * mtr_lm_dense_0\\n      * mtr_lm_dense_0_h1_16\\n      * mtr_lm_dense_1\\n      * mtr_lm_dense_2\\n      * mtr_lm_dense_3\\n      * mtr_lm_v1\\n      * mtr_lm_v1_h1_8\\n      * mtr_tr_dense_0\\n      * mtr_tr_dense_0_extra_logit\\n      * mtr_tr_dense_0_h16\\n      * mtr_tr_dense_0_h1_1\\n      * mtr_tr_dense_0_h1_16\\n      * mtr_tr_dense_0_h1_8\\n      * mtr_tr_dense_0_h2_16\\n      * mtr_tr_dense_0_h4\\n      * mtr_tr_dense_0_shared_kv\\n      * mtr_tr_dense_1\\n      * mtr_tr_dense_2\\n      * mtr_tr_dense_3\\n      * mtr_tr_dense_3_88\\n      * mtr_tr_dense_3_fast\\n      * mtr_tr_dense_local_0\\n      * mtr_tr_dense_local_0_h1_16\\n      * mtr_tr_dense_local_0_h1_16_shared\\n      * mtr_tr_dense_local_0_h1_16_shared_kv\\n      * mtr_tr_dense_local_0_h1_8_kv256\\n      * mtr_tr_dense_local_0_w8\\n      * mtr_tr_ende_deep\\n      * mtr_tr_ende_v0\\n      * mtr_tr_enfr_v0\\n    neural:\\n      * neural_gpu\\n    next:\\n      * next_frame_ae\\n      * next_frame_ae_tiny\\n      * next_frame_basic_deterministic\\n      * next_frame_basic_recurrent\\n      * next_frame_basic_stochastic\\n      * next_frame_basic_stochastic_discrete\\n      * next_frame_basic_stochastic_discrete_long\\n      * next_frame_emily\\n      * next_frame_epva\\n      * next_frame_glow_bair_qual\\n      * next_frame_glow_bair_quant\\n      * next_frame_glow_hparams\\n      * next_frame_glow_shapes\\n      * next_frame_l1\\n      * next_frame_l2\\n      * next_frame_pixel_noise\\n      * next_frame_pixel_noise_long\\n      * next_frame_sampling\\n      * next_frame_sampling_stochastic\\n      * next_frame_savp\\n      * next_frame_savp_gan\\n      * next_frame_savp_l2\\n      * next_frame_savp_vae\\n      * next_frame_small\\n      * next_frame_sv2p\\n      * next_frame_sv2p_atari\\n      * next_frame_sv2p_atari_deterministic\\n      * next_frame_sv2p_atari_softmax\\n      * next_frame_sv2p_atari_softmax_deterministic\\n      * next_frame_sv2p_cutoff\\n      * next_frame_sv2p_discrete\\n      * next_frame_sv2p_tiny\\n      * next_frame_sv2p_tiny_external\\n      * next_frame_tiny\\n      * next_frame_tpu\\n    ppo:\\n      * ppo_atari_base\\n      * ppo_base_v1\\n      * ppo_discrete_action_base\\n      * ppo_original_params\\n      * ppo_original_params_gamma90\\n      * ppo_original_params_gamma95\\n      * ppo_original_tiny\\n      * ppo_original_world_model\\n      * ppo_original_world_model_stochastic_discrete\\n      * ppo_pong_ae_base\\n      * ppo_tiny_world_model\\n      * ppo_ttt_params\\n    resnet:\\n      * resnet_101\\n      * resnet_152\\n      * resnet_18\\n      * resnet_200\\n      * resnet_34\\n      * resnet_50\\n      * resnet_cifar_15\\n      * resnet_cifar_32\\n      * resnet_cifar_32_td_unit_05_05\\n      * resnet_cifar_32_td_unit_no_drop\\n      * resnet_cifar_32_td_weight_05_05\\n      * resnet_imagenet_102\\n      * resnet_imagenet_34\\n      * resnet_imagenet_34_td_unit_05_05\\n      * resnet_imagenet_34_td_unit_no_drop\\n      * resnet_imagenet_34_td_weight_05_05\\n    revnet:\\n      * revnet_104\\n      * revnet_110_cifar\\n      * revnet_164_cifar\\n      * revnet_38_cifar\\n    rlmf:\\n      * rlmf_base\\n      * rlmf_dqn_tiny\\n      * rlmf_eval\\n      * rlmf_original\\n      * rlmf_tictactoe\\n      * rlmf_tiny\\n    shake:\\n      * shake_shake_quick\\n    shakeshake:\\n      * shakeshake_big\\n      * shakeshake_small\\n      * shakeshake_tpu\\n    sliced:\\n      * sliced_gan\\n    slicenet:\\n      * slicenet_1\\n      * slicenet_1noam\\n      * slicenet_1tiny\\n    super:\\n      * super_lm_b8k\\n      * super_lm_base\\n      * super_lm_big\\n      * super_lm_big_tpu\\n      * super_lm_conv\\n      * super_lm_high_mix\\n      * super_lm_low_mix\\n      * super_lm_moe\\n      * super_lm_moe_4b_diet\\n      * super_lm_moe_h4\\n      * super_lm_tpu\\n      * super_lm_tpu_memtest\\n    text:\\n      * text_cnn_base\\n    transformer:\\n      * transformer_ada_lmpackedbase\\n      * transformer_ada_lmpackedbase_dialog\\n      * transformer_ada_lmpackedbase_relative\\n      * transformer_ae_a3\\n      * transformer_ae_a6\\n      * transformer_ae_a8\\n      * transformer_ae_base\\n      * transformer_ae_base_ablation_1\\n      * transformer_ae_base_ablation_2\\n      * transformer_ae_base_ablation_3\\n      * transformer_ae_base_ablation_4\\n      * transformer_ae_base_ablation_5\\n      * transformer_ae_base_iaf\\n      * transformer_ae_base_noatt\\n      * transformer_ae_base_tpu\\n      * transformer_ae_small\\n      * transformer_ae_small_noatt\\n      * transformer_base\\n      * transformer_base_bs1\\n      * transformer_base_bs10\\n      * transformer_base_bs2\\n      * transformer_base_bs3\\n      * transformer_base_bs4\\n      * transformer_base_bs5\\n      * transformer_base_bs6\\n      * transformer_base_bs7\\n      * transformer_base_bs8\\n      * transformer_base_bs9\\n      * transformer_base_multistep8\\n      * transformer_base_single_gpu\\n      * transformer_base_v1\\n      * transformer_base_v2\\n      * transformer_base_v3\\n      * transformer_base_vq1_16_nb1_packed_dan_b01_scales\\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales\\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales_dialog\\n      * transformer_base_vq_ada_32ex_packed\\n      * transformer_big\\n      * transformer_big_bs1\\n      * transformer_big_dr1\\n      * transformer_big_dr2\\n      * transformer_big_enfr\\n      * transformer_big_enfr_tpu\\n      * transformer_big_single_gpu\\n      * transformer_big_tpu\\n      * transformer_cifar10_memory_v0\\n      * transformer_clean\\n      * transformer_clean_big\\n      * transformer_clean_big_tpu\\n      * transformer_common_voice\\n      * transformer_common_voice_tpu\\n      * transformer_dr0\\n      * transformer_dr2\\n      * transformer_fairseq_fp16_activation_big\\n      * transformer_ff1024\\n      * transformer_ff4096\\n      * transformer_h1\\n      * transformer_h16\\n      * transformer_h32\\n      * transformer_h4\\n      * transformer_hs1024\\n      * transformer_hs256\\n      * transformer_imagenet64_memory_v0\\n      * transformer_k128\\n      * transformer_k256\\n      * transformer_l10\\n      * transformer_l2\\n      * transformer_l4\\n      * transformer_l8\\n      * transformer_librispeech\\n      * transformer_librispeech_tpu\\n      * transformer_librispeech_tpu_v1\\n      * transformer_librispeech_tpu_v2\\n      * transformer_librispeech_v1\\n      * transformer_librispeech_v2\\n      * transformer_lm_tpu_0\\n      * transformer_lm_tpu_1\\n      * transformer_ls0\\n      * transformer_ls2\\n      * transformer_mlperf_tpu\\n      * transformer_moe_12k\\n      * transformer_moe_2k\\n      * transformer_moe_8k\\n      * transformer_moe_8k_lm\\n      * transformer_moe_base\\n      * transformer_moe_prepend_8k\\n      * transformer_nat_base\\n      * transformer_nat_big\\n      * transformer_nat_small\\n      * transformer_packed_tpu\\n      * transformer_parameter_attention_a\\n      * transformer_parameter_attention_b\\n      * transformer_parsing_base\\n      * transformer_parsing_big\\n      * transformer_parsing_ice\\n      * transformer_prepend\\n      * transformer_prepend_v1\\n      * transformer_prepend_v2\\n      * transformer_relative\\n      * transformer_relative_big\\n      * transformer_relative_tiny\\n      * transformer_revnet_base\\n      * transformer_revnet_big\\n      * transformer_sketch\\n      * transformer_small\\n      * transformer_small_tpu\\n      * transformer_supervised_attention\\n      * transformer_symshard_base\\n      * transformer_symshard_h4\\n      * transformer_symshard_lm_0\\n      * transformer_symshard_sh4\\n      * transformer_tall\\n      * transformer_tall_big\\n      * transformer_tall_finetune_textclass\\n      * transformer_tall_finetune_tied\\n      * transformer_tall_finetune_uniencdec\\n      * transformer_tall_pretrain_lm\\n      * transformer_tall_pretrain_lm_tpu\\n      * transformer_tall_pretrain_lm_tpu_adafactor\\n      * transformer_tall_pretrain_lm_tpu_adafactor_large\\n      * transformer_tall_train_tied\\n      * transformer_tall_train_uniencdec\\n      * transformer_teeny\\n      * transformer_test\\n      * transformer_timeseries\\n      * transformer_timeseries_tpu\\n      * transformer_tiny\\n      * transformer_tiny_bs1\\n      * transformer_tiny_bs2\\n      * transformer_tiny_bs3\\n      * transformer_tiny_tpu\\n      * transformer_topk_16_packed\\n      * transformer_tpu\\n      * transformer_tpu_1b\\n      * transformer_tpu_bf16_activation\\n      * transformer_tpu_with_conv\\n      * transformer_wikitext103_l16k_memory_v0\\n      * transformer_wikitext103_l4k_memory_v0\\n      * transformer_wikitext103_l4k_v0\\n    universal:\\n      * universal_transformer_base\\n      * universal_transformer_base_fp16\\n      * universal_transformer_base_tpu\\n      * universal_transformer_big\\n      * universal_transformer_dwa_base\\n      * universal_transformer_gru_base\\n      * universal_transformer_highway_base\\n      * universal_transformer_lstm_base\\n      * universal_transformer_lstm_tall\\n      * universal_transformer_mix_after_ut_base\\n      * universal_transformer_mix_before_ut_base\\n      * universal_transformer_position_random_timing_tiny\\n      * universal_transformer_position_step_timing_tiny\\n      * universal_transformer_sepconv_base\\n      * universal_transformer_sepconv_big\\n      * universal_transformer_skip_base\\n      * universal_transformer_small\\n      * universal_transformer_small_dropconnect\\n      * universal_transformer_step_sinusoid_timing_tiny\\n      * universal_transformer_tall\\n      * universal_transformer_teeny\\n      * universal_transformer_tiny\\n    vqa:\\n      * vqa_attention_base\\n      * vqa_attention_drop01_dna\\n      * vqa_attention_feature_base\\n      * vqa_attention_feature_batch1024\\n      * vqa_attention_feature_batch1024_dnz\\n      * vqa_attention_feature_batch1024_dnz_l2\\n      * vqa_attention_feature_batch1024_dnz_noscaledp\\n      * vqa_attention_feature_batch1024_drop01\\n      * vqa_attention_feature_batch1024_drop01_dna\\n      * vqa_attention_feature_batch1024_drop01_dna_concat\\n      * vqa_attention_feature_batch1024_lstmlayernorm\\n      * vqa_attention_feature_batch1024_numglimps1\\n      * vqa_attention_feature_batch512\\n      * vqa_attention_feature_dna\\n      * vqa_attention_feature_dnz\\n      * vqa_attention_feature_dnz_l2\\n      * vqa_attention_feature_dnz_noscaledp\\n      * vqa_attention_feature_hidden1024\\n      * vqa_attention_feature_imagefeat1024\\n      * vqa_attention_feature_imagefeat512\\n      * vqa_attention_feature_initializer\\n      * vqa_attention_feature_lstmlayernorm\\n      * vqa_attention_feature_nonormalization\\n      * vqa_attention_feature_numglimps1\\n      * vqa_attention_numglimps1\\n      * vqa_recurrent_self_attention_base\\n      * vqa_recurrent_self_attention_big\\n      * vqa_recurrent_self_attention_big_l4\\n      * vqa_recurrent_self_attention_drop1\\n      * vqa_recurrent_self_attention_drop3\\n      * vqa_recurrent_self_attention_gru\\n      * vqa_recurrent_self_attention_highway\\n      * vqa_recurrent_self_attention_l4\\n      * vqa_recurrent_self_attention_l8\\n      * vqa_recurrent_self_attention_ls2\\n      * vqa_recurrent_self_attention_mix_before_ut\\n      * vqa_recurrent_self_attention_small\\n      * vqa_self_attention_base\\n      * vqa_self_attention_feature\\n      * vqa_self_attention_feature_batch1024\\n      * vqa_self_attention_feature_batch1024_big\\n      * vqa_self_attention_feature_batch1024_drop03\\n      * vqa_self_attention_feature_batch1024_exp\\n      * vqa_self_attention_feature_batch1024_hidden6\\n      * vqa_self_attention_feature_batch1024_hidden6_big\\n      * vqa_self_attention_feature_lr5\\n    wiki:\\n      * wiki_2x2_base\\n      * wiki_2x2_local\\n      * wiki_2x2_v1\\n    xception:\\n      * xception_base\\n      * xception_tiny\\n      * xception_tiny_tpu\\n    xmoe2:\\n      * xmoe2_dense\\n      * xmoe2_dense_0\\n      * xmoe2_dense_1\\n      * xmoe2_dense_2\\n      * xmoe2_dense_3\\n      * xmoe2_tiny\\n      * xmoe2_v1\\n      * xmoe2_v1_l4k\\n      * xmoe2_v1_l4k_compressed_c4\\n      * xmoe2_v1_l4k_compressed_c8\\n      * xmoe2_v1_l4k_global_only\\n      * xmoe2_v1_l4k_local_only\\n      * xmoe2_v1_x128\\n    xmoe:\\n      * xmoe_2d\\n      * xmoe_2d_c15\\n      * xmoe_2d_debug\\n      * xmoe_2d_x64\\n      * xmoe_dense_4k\\n      * xmoe_dense_64k\\n      * xmoe_dense_8k\\n      * xmoe_top_2\\n      * xmoe_top_2_c15\\n      * xmoe_tr_1d\\n      * xmoe_tr_2d\\n      * xmoe_tr_dense_2k\\n      * xmoe_tr_dense_32k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3e54a7a35d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttentionVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensor2tensor/visualization/visualization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hparams_set, model_name, data_dir, problem_name, beam_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m       self, hparams_set, model_name, data_dir, problem_name, beam_size=1):\n\u001b[1;32m     39\u001b[0m     inputs, targets, samples, att_mats = build_model(\n\u001b[0;32m---> 40\u001b[0;31m         hparams_set, model_name, data_dir, problem_name, beam_size=beam_size)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Fetch the problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensor2tensor/visualization/visualization.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(hparams_set, model_name, data_dir, problem_name, beam_size)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \"\"\"\n\u001b[1;32m    133\u001b[0m   hparams = trainer_lib.create_hparams(\n\u001b[0;32m--> 134\u001b[0;31m       hparams_set, data_dir=data_dir, problem_name=problem_name)\n\u001b[0m\u001b[1;32m    135\u001b[0m   translate_model = registry.model(model_name)(\n\u001b[1;32m    136\u001b[0m       hparams, tf.estimator.ModeKeys.EVAL)\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/hparams_lib.py\u001b[0m in \u001b[0;36mcreate_hparams\u001b[0;34m(hparams_set, hparams_overrides_str, data_dir, problem_name, hparams_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m                    hparams_path=None):\n\u001b[1;32m     47\u001b[0m   \u001b[0;34m\"\"\"Create HParams with data_dir and problem hparams, if kwargs provided.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhparams_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_hparams_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensor2tensor/utils/registry.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m       raise KeyError(\"%s never registered with registry %s. Available:\\n %s\" %\n\u001b[0;32m--> 254\u001b[0;31m                      (key, self.name, display_list_by_prefix(sorted(self), 4)))\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'transformer_chat never registered with registry hparams. Available:\\n     adaptive:\\n      * adaptive_universal_transformer_base\\n      * adaptive_universal_transformer_base_dropout03\\n      * adaptive_universal_transformer_base_dropout05\\n      * adaptive_universal_transformer_base_tpu\\n      * adaptive_universal_transformer_concat_tiny\\n      * adaptive_universal_transformer_global_base\\n      * adaptive_universal_transformer_global_base_tpu\\n      * adaptive_universal_transformer_mix_after_ut_base\\n      * adaptive_universal_transformer_mix_before_ut_base\\n      * adaptive_universal_transformer_multilayer_hard\\n      * adaptive_universal_transformer_multilayer_tpu\\n      * adaptive_universal_transformer_position_random_timing_tiny\\n      * adaptive_universal_transformer_small\\n      * adaptive_universal_transformer_tall\\n      * adaptive_universal_transformer_tall_actlossw0\\n      * adaptive_universal_transformer_tall_actlossw001\\n      * adaptive_universal_transformer_tiny\\n      * adaptive_universal_transformer_with_sru_base\\n    afx:\\n      * afx_adafactor\\n      * afx_adam\\n      * afx_base\\n      * afx_clip\\n      * afx_clip2\\n      * afx_clip_factored\\n      * afx_factored\\n      * afx_fast\\n      * afx_mimic_adam\\n      * afx_pow05\\n      * afx_pow08\\n      * afx_pow08_clip\\n      * afx_pow10\\n      * afx_relative\\n      * afx_small\\n      * afx_small_bfloat16\\n      * afx_small_p10\\n      * afx_small_p11\\n      * afx_small_p12\\n      * afx_small_p16\\n      * afx_small_p8\\n      * afx_unscale\\n      * afx_unscale_relative\\n    aligned:\\n      * aligned_8k\\n      * aligned_8k_grouped\\n      * aligned_base\\n      * aligned_grouped\\n      * aligned_local\\n      * aligned_local_1k\\n      * aligned_local_expert\\n      * aligned_lsh\\n      * aligned_memory_efficient\\n      * aligned_moe\\n      * aligned_no_att\\n      * aligned_no_timing\\n      * aligned_pos_emb\\n      * aligned_pseudolocal\\n      * aligned_pseudolocal_256\\n    attention:\\n      * attention_lm_11k\\n      * attention_lm_12k\\n      * attention_lm_16k\\n      * attention_lm_ae_extended\\n      * attention_lm_attention_moe_tiny\\n      * attention_lm_base\\n      * attention_lm_hybrid_v2\\n      * attention_lm_moe_24b_diet\\n      * attention_lm_moe_32b_diet\\n      * attention_lm_moe_base\\n      * attention_lm_moe_base_ae\\n      * attention_lm_moe_base_hybrid\\n      * attention_lm_moe_base_local\\n      * attention_lm_moe_base_long_seq\\n      * attention_lm_moe_base_memeff\\n      * attention_lm_moe_large\\n      * attention_lm_moe_large_diet\\n      * attention_lm_moe_memory_efficient\\n      * attention_lm_moe_small\\n      * attention_lm_moe_tiny\\n      * attention_lm_moe_translation\\n      * attention_lm_moe_unscramble_base\\n      * attention_lm_no_moe_small\\n      * attention_lm_small\\n      * attention_lm_translation\\n      * attention_lm_translation_full_attention\\n      * attention_lm_translation_l12\\n    autoencoder:\\n      * autoencoder_autoregressive\\n      * autoencoder_basic\\n      * autoencoder_basic_discrete\\n      * autoencoder_discrete_cifar\\n      * autoencoder_discrete_pong\\n      * autoencoder_discrete_tiny\\n      * autoencoder_ordered_discrete\\n      * autoencoder_ordered_discrete_hs256\\n      * autoencoder_ordered_discrete_image64\\n      * autoencoder_ordered_discrete_patched\\n      * autoencoder_ordered_discrete_single\\n      * autoencoder_ordered_discrete_vq\\n      * autoencoder_ordered_text\\n      * autoencoder_ordered_text_small\\n      * autoencoder_residual\\n      * autoencoder_residual_discrete\\n      * autoencoder_residual_discrete_big\\n      * autoencoder_residual_text\\n      * autoencoder_stacked\\n    basic:\\n      * basic_1\\n      * basic_fc_small\\n      * basic_policy_parameters\\n    bytenet:\\n      * bytenet_base\\n    cycle:\\n      * cycle_gan_small\\n    denoise:\\n      * denoise_dense_2_m30\\n      * denoise_m15\\n      * denoise_m30\\n      * denoise_t15\\n      * denoise_v1_m15\\n      * denoise_v1_m30\\n      * denoise_v1_m50\\n      * denoise_v1_t15\\n      * denoise_v1_z15\\n      * denoise_z15\\n    discrete:\\n      * discrete_random_action_base\\n    distill:\\n      * distill_resnet_32_to_15_cifar20x5\\n    dqn:\\n      * dqn_atari_base\\n      * dqn_original_params\\n    evolved:\\n      * evolved_transformer_base\\n      * evolved_transformer_base_tpu\\n      * evolved_transformer_big\\n      * evolved_transformer_big_tpu\\n    frame:\\n      * frame_glow_hparams\\n    gene:\\n      * gene_expression_conv_base\\n    glow:\\n      * glow_hparams\\n    image:\\n      * image_transformer2d_base\\n      * image_transformer_base\\n    imagetransformer1d:\\n      * imagetransformer1d_base_12l_64by64\\n      * imagetransformer1d_base_8l_64by64\\n    imagetransformer2d:\\n      * imagetransformer2d_base\\n      * imagetransformer2d_base_12l_8_16_big\\n      * imagetransformer2d_base_12l_8_64_64by64\\n      * imagetransformer2d_base_14l_8_16_big\\n      * imagetransformer2d_base_14l_8_16_big_uncond\\n      * imagetransformer2d_base_8l_8_16\\n      * imagetransformer2d_base_8l_8_16_big\\n      * imagetransformer2d_base_8l_8_16_big_16k\\n      * imagetransformer2d_base_8l_8_16_ls\\n      * imagetransformer2d_base_8l_8_32_big\\n      * imagetransformer2d_base_8l_8_64_64by64\\n      * imagetransformer2d_tiny\\n    imagetransformer:\\n      * imagetransformer_ae_cifar\\n      * imagetransformer_b10l_4h_big_uncond_dr01_tpu\\n      * imagetransformer_b10l_4h_big_uncond_dr03_lr025_tpu\\n      * imagetransformer_b10l_4h_big_uncond_dr03_tpu\\n      * imagetransformer_b10l_dr03_moe_tpu\\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr01_im\\n      * imagetransformer_b12l_4h_b128_h512_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_b128_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_b256_uncond_dr03_rel_tpu\\n      * imagetransformer_b12l_4h_b256_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_big_uncond_dr03_lr025_tpu\\n      * imagetransformer_b12l_4h_big_uncond_dr03_tpu\\n      * imagetransformer_b12l_4h_uncond_dr03_tpu\\n      * imagetransformer_b12l_8h_b256_uncond_dr03_tpu\\n      * imagetransformer_bas8l_8h_big_uncond_dr03_imgnet\\n      * imagetransformer_base\\n      * imagetransformer_base_10l_16h_big_dr01_imgnet\\n      * imagetransformer_base_10l_16h_big_dr01_moe_imgnet\\n      * imagetransformer_base_10l_16h_big_uncond_dr01_imgnet\\n      * imagetransformer_base_10l_8h_big_cond_dr03_dan\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64\\n      * imagetransformer_base_10l_8h_big_uncond_dr03_dan_64_2d\\n      * imagetransformer_base_12l_8h_big\\n      * imagetransformer_base_12l_8h_big_uncond\\n      * imagetransformer_base_14l_8h_big\\n      * imagetransformer_base_14l_8h_big_dr01\\n      * imagetransformer_base_14l_8h_big_uncond\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_128\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_b\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_c\\n      * imagetransformer_base_8l_8h_big_cond_dr03_dan_dilated_d\\n      * imagetransformer_base_imagenet_tpu\\n      * imagetransformer_base_rel\\n      * imagetransformer_base_tpu\\n      * imagetransformer_cifar10_base\\n      * imagetransformer_cifar10_base_dmol\\n      * imagetransformer_imagenet32_base\\n      * imagetransformer_moe_tiny\\n      * imagetransformer_sep_channels\\n      * imagetransformer_sep_channels_12l_16h_imagenet_large\\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc\\n      * imagetransformer_sep_channels_16l_16h_imgnet_lrg_loc_128\\n      * imagetransformer_sep_channels_8l\\n      * imagetransformer_sep_channels_8l_8h\\n      * imagetransformer_sep_channels_8l_8h_local_and_global_att\\n      * imagetransformer_sep_channels_8l_multipos3\\n      * imagetransformer_sep_channels_8l_tpu\\n      * imagetransformer_sep_output_channels_8l_local_and_global_att\\n      * imagetransformer_tiny\\n      * imagetransformer_tiny_tpu\\n    imagetransformerpp:\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_a\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_b\\n      * imagetransformerpp_base_10l_8h_big_uncond_dr03_dan_g\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_k\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_l\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_bs1\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_rel\\n      * imagetransformerpp_base_12l_8h_big_uncond_dr03_dan_m_relsh\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_eval\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p\\n      * imagetransformerpp_base_14l_8h_big_uncond_dr03_dan_p_bs1\\n      * imagetransformerpp_base_5l_8h_big_uncond_dr00_dan_g_bs1\\n      * imagetransformerpp_base_5l_8h_dr00_dan_g_bs1_adafactor\\n      * imagetransformerpp_base_6l_8h_dr00_dan_g_bs1_adafactor\\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan\\n      * imagetransformerpp_base_8l_8h_big_cond_dr03_dan_a\\n      * imagetransformerpp_sep_channels_8l_8h\\n      * imagetransformerpp_tiny\\n    img2img:\\n      * img2img_transformer2d_base\\n      * img2img_transformer2d_n103\\n      * img2img_transformer2d_n24\\n      * img2img_transformer2d_n3\\n      * img2img_transformer2d_n31\\n      * img2img_transformer2d_n44\\n      * img2img_transformer2d_q1\\n      * img2img_transformer2d_q2\\n      * img2img_transformer2d_q3\\n      * img2img_transformer2d_tiny\\n      * img2img_transformer_b1\\n      * img2img_transformer_b2\\n      * img2img_transformer_b3\\n      * img2img_transformer_b3_bs1\\n      * img2img_transformer_b3_bs10\\n      * img2img_transformer_b3_bs2\\n      * img2img_transformer_b3_bs3\\n      * img2img_transformer_b3_bs4\\n      * img2img_transformer_b3_bs5\\n      * img2img_transformer_b3_bs6\\n      * img2img_transformer_b3_bs7\\n      * img2img_transformer_b3_bs8\\n      * img2img_transformer_b3_bs9\\n      * img2img_transformer_base\\n      * img2img_transformer_base_tpu\\n      * img2img_transformer_dilated\\n      * img2img_transformer_tiny\\n      * img2img_transformer_tiny_tpu\\n    lmx:\\n      * lmx_base\\n      * lmx_h1k_f4k\\n      * lmx_h1k_f64k\\n      * lmx_h2k_f8k\\n      * lmx_h3k_f12k\\n      * lmx_h4k_f16k\\n      * lmx_moe\\n      * lmx_moe_h1k_f4k_x32\\n      * lmx_moe_h1k_f8k_x16\\n      * lmx_relative\\n      * lmx_relative_nopos\\n    lstm:\\n      * lstm_area_attention_base\\n      * lstm_area_attention_char\\n      * lstm_area_attention_char_enfr\\n      * lstm_area_attention_enfr\\n      * lstm_asr_v1\\n      * lstm_attention\\n      * lstm_bahdanau_attention\\n      * lstm_bahdanau_attention_multi\\n      * lstm_luong_attention\\n      * lstm_luong_attention_multi\\n      * lstm_seq2seq\\n    mqp:\\n      * mqp_ende_base\\n      * mqp_ende_h1_ff6784\\n      * mqp_ende_h1_kv1024\\n      * mqp_ende_h2_ff6400\\n      * mqp_ende_h2_kv512\\n      * mqp_ende_h2_kv64_ff6784\\n      * mqp_ende_h4_ff5632\\n      * mqp_ende_h4_kv256\\n      * mqp_ende_h4_kv32_ff6784\\n      * mqp_ende_h8_kv16_ff6784\\n      * mqp_ende_local\\n      * mqp_ende_mq8\\n      * mqp_ende_mq8_ff5440\\n      * mqp_ende_mq8_ff5440_local\\n      * mqp_lm1b_base\\n      * mqp_lm1b_h1_ff9984\\n      * mqp_lm1b_h2_kv64_ff9984\\n      * mqp_lm1b_h4_kv32_ff9984\\n      * mqp_lm1b_h8_kv16_ff9984\\n      * mqp_lm1b_mq8\\n      * mqp_lm1b_mq8_ff9088\\n    mtf:\\n      * mtf_bitransformer_all_layers_tiny\\n      * mtf_bitransformer_base\\n      * mtf_bitransformer_tiny\\n      * mtf_image_transformer_base\\n      * mtf_image_transformer_base_cifar\\n      * mtf_image_transformer_base_imagenet\\n      * mtf_image_transformer_base_imagenet_mp\\n      * mtf_image_transformer_base_imagenet_mp128\\n      * mtf_image_transformer_base_imagenet_mp64\\n      * mtf_image_transformer_base_imagenet_mp_sp\\n      * mtf_image_transformer_base_single\\n      * mtf_image_transformer_cifar_4x\\n      * mtf_image_transformer_cifar_mp_4x\\n      * mtf_image_transformer_length_sharded\\n      * mtf_image_transformer_single\\n      * mtf_image_transformer_tiny\\n      * mtf_image_transformer_tiny_8gpu\\n      * mtf_image_transformer_tiny_spatial1d\\n      * mtf_image_transformer_tiny_spatial2d\\n      * mtf_resnet_base\\n      * mtf_resnet_base_cifar\\n      * mtf_resnet_base_single\\n      * mtf_resnet_single\\n      * mtf_resnet_tiny\\n      * mtf_transformer_base\\n      * mtf_transformer_base_lm\\n      * mtf_transformer_enc_single\\n      * mtf_transformer_lm_baseline\\n      * mtf_transformer_paper_lm_0\\n      * mtf_transformer_paper_lm_1\\n      * mtf_transformer_paper_lm_2\\n      * mtf_transformer_paper_lm_3\\n      * mtf_transformer_paper_lm_4\\n      * mtf_transformer_paper_lm_5\\n      * mtf_transformer_paper_lm_m1\\n      * mtf_transformer_paper_tr_0\\n      * mtf_transformer_paper_tr_0_a32\\n      * mtf_transformer_paper_tr_0_mesh_128\\n      * mtf_transformer_paper_tr_0_mesh_512\\n      * mtf_transformer_paper_tr_0_mesh_8\\n      * mtf_transformer_paper_tr_0_mesh_8_v2\\n      * mtf_transformer_paper_tr_0_nf\\n      * mtf_transformer_paper_tr_1\\n      * mtf_transformer_paper_tr_2\\n      * mtf_transformer_paper_tr_3\\n      * mtf_transformer_paper_tr_4\\n      * mtf_transformer_paper_tr_4_mesh_16_8\\n      * mtf_transformer_paper_tr_6_mesh_64_8\\n      * mtf_transformer_paper_tr_m1\\n      * mtf_transformer_single\\n      * mtf_transformer_tiny\\n      * mtf_transformer_tiny_8gpu\\n      * mtf_transformer_tiny_denoising\\n      * mtf_transformer_tiny_lm\\n      * mtf_unitransformer_all_layers_tiny\\n      * mtf_unitransformer_base\\n      * mtf_unitransformer_tiny\\n    mtr:\\n      * mtr_lm_dense\\n      * mtr_lm_dense_0\\n      * mtr_lm_dense_0_h1_16\\n      * mtr_lm_dense_1\\n      * mtr_lm_dense_2\\n      * mtr_lm_dense_3\\n      * mtr_lm_v1\\n      * mtr_lm_v1_h1_8\\n      * mtr_tr_dense_0\\n      * mtr_tr_dense_0_extra_logit\\n      * mtr_tr_dense_0_h16\\n      * mtr_tr_dense_0_h1_1\\n      * mtr_tr_dense_0_h1_16\\n      * mtr_tr_dense_0_h1_8\\n      * mtr_tr_dense_0_h2_16\\n      * mtr_tr_dense_0_h4\\n      * mtr_tr_dense_0_shared_kv\\n      * mtr_tr_dense_1\\n      * mtr_tr_dense_2\\n      * mtr_tr_dense_3\\n      * mtr_tr_dense_3_88\\n      * mtr_tr_dense_3_fast\\n      * mtr_tr_dense_local_0\\n      * mtr_tr_dense_local_0_h1_16\\n      * mtr_tr_dense_local_0_h1_16_shared\\n      * mtr_tr_dense_local_0_h1_16_shared_kv\\n      * mtr_tr_dense_local_0_h1_8_kv256\\n      * mtr_tr_dense_local_0_w8\\n      * mtr_tr_ende_deep\\n      * mtr_tr_ende_v0\\n      * mtr_tr_enfr_v0\\n    neural:\\n      * neural_gpu\\n    next:\\n      * next_frame_ae\\n      * next_frame_ae_tiny\\n      * next_frame_basic_deterministic\\n      * next_frame_basic_recurrent\\n      * next_frame_basic_stochastic\\n      * next_frame_basic_stochastic_discrete\\n      * next_frame_basic_stochastic_discrete_long\\n      * next_frame_emily\\n      * next_frame_epva\\n      * next_frame_glow_bair_qual\\n      * next_frame_glow_bair_quant\\n      * next_frame_glow_hparams\\n      * next_frame_glow_shapes\\n      * next_frame_l1\\n      * next_frame_l2\\n      * next_frame_pixel_noise\\n      * next_frame_pixel_noise_long\\n      * next_frame_sampling\\n      * next_frame_sampling_stochastic\\n      * next_frame_savp\\n      * next_frame_savp_gan\\n      * next_frame_savp_l2\\n      * next_frame_savp_vae\\n      * next_frame_small\\n      * next_frame_sv2p\\n      * next_frame_sv2p_atari\\n      * next_frame_sv2p_atari_deterministic\\n      * next_frame_sv2p_atari_softmax\\n      * next_frame_sv2p_atari_softmax_deterministic\\n      * next_frame_sv2p_cutoff\\n      * next_frame_sv2p_discrete\\n      * next_frame_sv2p_tiny\\n      * next_frame_sv2p_tiny_external\\n      * next_frame_tiny\\n      * next_frame_tpu\\n    ppo:\\n      * ppo_atari_base\\n      * ppo_base_v1\\n      * ppo_discrete_action_base\\n      * ppo_original_params\\n      * ppo_original_params_gamma90\\n      * ppo_original_params_gamma95\\n      * ppo_original_tiny\\n      * ppo_original_world_model\\n      * ppo_original_world_model_stochastic_discrete\\n      * ppo_pong_ae_base\\n      * ppo_tiny_world_model\\n      * ppo_ttt_params\\n    resnet:\\n      * resnet_101\\n      * resnet_152\\n      * resnet_18\\n      * resnet_200\\n      * resnet_34\\n      * resnet_50\\n      * resnet_cifar_15\\n      * resnet_cifar_32\\n      * resnet_cifar_32_td_unit_05_05\\n      * resnet_cifar_32_td_unit_no_drop\\n      * resnet_cifar_32_td_weight_05_05\\n      * resnet_imagenet_102\\n      * resnet_imagenet_34\\n      * resnet_imagenet_34_td_unit_05_05\\n      * resnet_imagenet_34_td_unit_no_drop\\n      * resnet_imagenet_34_td_weight_05_05\\n    revnet:\\n      * revnet_104\\n      * revnet_110_cifar\\n      * revnet_164_cifar\\n      * revnet_38_cifar\\n    rlmf:\\n      * rlmf_base\\n      * rlmf_dqn_tiny\\n      * rlmf_eval\\n      * rlmf_original\\n      * rlmf_tictactoe\\n      * rlmf_tiny\\n    shake:\\n      * shake_shake_quick\\n    shakeshake:\\n      * shakeshake_big\\n      * shakeshake_small\\n      * shakeshake_tpu\\n    sliced:\\n      * sliced_gan\\n    slicenet:\\n      * slicenet_1\\n      * slicenet_1noam\\n      * slicenet_1tiny\\n    super:\\n      * super_lm_b8k\\n      * super_lm_base\\n      * super_lm_big\\n      * super_lm_big_tpu\\n      * super_lm_conv\\n      * super_lm_high_mix\\n      * super_lm_low_mix\\n      * super_lm_moe\\n      * super_lm_moe_4b_diet\\n      * super_lm_moe_h4\\n      * super_lm_tpu\\n      * super_lm_tpu_memtest\\n    text:\\n      * text_cnn_base\\n    transformer:\\n      * transformer_ada_lmpackedbase\\n      * transformer_ada_lmpackedbase_dialog\\n      * transformer_ada_lmpackedbase_relative\\n      * transformer_ae_a3\\n      * transformer_ae_a6\\n      * transformer_ae_a8\\n      * transformer_ae_base\\n      * transformer_ae_base_ablation_1\\n      * transformer_ae_base_ablation_2\\n      * transformer_ae_base_ablation_3\\n      * transformer_ae_base_ablation_4\\n      * transformer_ae_base_ablation_5\\n      * transformer_ae_base_iaf\\n      * transformer_ae_base_noatt\\n      * transformer_ae_base_tpu\\n      * transformer_ae_small\\n      * transformer_ae_small_noatt\\n      * transformer_base\\n      * transformer_base_bs1\\n      * transformer_base_bs10\\n      * transformer_base_bs2\\n      * transformer_base_bs3\\n      * transformer_base_bs4\\n      * transformer_base_bs5\\n      * transformer_base_bs6\\n      * transformer_base_bs7\\n      * transformer_base_bs8\\n      * transformer_base_bs9\\n      * transformer_base_multistep8\\n      * transformer_base_single_gpu\\n      * transformer_base_v1\\n      * transformer_base_v2\\n      * transformer_base_v3\\n      * transformer_base_vq1_16_nb1_packed_dan_b01_scales\\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales\\n      * transformer_base_vq1_16_nb1_packed_nda_b01_scales_dialog\\n      * transformer_base_vq_ada_32ex_packed\\n      * transformer_big\\n      * transformer_big_bs1\\n      * transformer_big_dr1\\n      * transformer_big_dr2\\n      * transformer_big_enfr\\n      * transformer_big_enfr_tpu\\n      * transformer_big_single_gpu\\n      * transformer_big_tpu\\n      * transformer_cifar10_memory_v0\\n      * transformer_clean\\n      * transformer_clean_big\\n      * transformer_clean_big_tpu\\n      * transformer_common_voice\\n      * transformer_common_voice_tpu\\n      * transformer_dr0\\n      * transformer_dr2\\n      * transformer_fairseq_fp16_activation_big\\n      * transformer_ff1024\\n      * transformer_ff4096\\n      * transformer_h1\\n      * transformer_h16\\n      * transformer_h32\\n      * transformer_h4\\n      * transformer_hs1024\\n      * transformer_hs256\\n      * transformer_imagenet64_memory_v0\\n      * transformer_k128\\n      * transformer_k256\\n      * transformer_l10\\n      * transformer_l2\\n      * transformer_l4\\n      * transformer_l8\\n      * transformer_librispeech\\n      * transformer_librispeech_tpu\\n      * transformer_librispeech_tpu_v1\\n      * transformer_librispeech_tpu_v2\\n      * transformer_librispeech_v1\\n      * transformer_librispeech_v2\\n      * transformer_lm_tpu_0\\n      * transformer_lm_tpu_1\\n      * transformer_ls0\\n      * transformer_ls2\\n      * transformer_mlperf_tpu\\n      * transformer_moe_12k\\n      * transformer_moe_2k\\n      * transformer_moe_8k\\n      * transformer_moe_8k_lm\\n      * transformer_moe_base\\n      * transformer_moe_prepend_8k\\n      * transformer_nat_base\\n      * transformer_nat_big\\n      * transformer_nat_small\\n      * transformer_packed_tpu\\n      * transformer_parameter_attention_a\\n      * transformer_parameter_attention_b\\n      * transformer_parsing_base\\n      * transformer_parsing_big\\n      * transformer_parsing_ice\\n      * transformer_prepend\\n      * transformer_prepend_v1\\n      * transformer_prepend_v2\\n      * transformer_relative\\n      * transformer_relative_big\\n      * transformer_relative_tiny\\n      * transformer_revnet_base\\n      * transformer_revnet_big\\n      * transformer_sketch\\n      * transformer_small\\n      * transformer_small_tpu\\n      * transformer_supervised_attention\\n      * transformer_symshard_base\\n      * transformer_symshard_h4\\n      * transformer_symshard_lm_0\\n      * transformer_symshard_sh4\\n      * transformer_tall\\n      * transformer_tall_big\\n      * transformer_tall_finetune_textclass\\n      * transformer_tall_finetune_tied\\n      * transformer_tall_finetune_uniencdec\\n      * transformer_tall_pretrain_lm\\n      * transformer_tall_pretrain_lm_tpu\\n      * transformer_tall_pretrain_lm_tpu_adafactor\\n      * transformer_tall_pretrain_lm_tpu_adafactor_large\\n      * transformer_tall_train_tied\\n      * transformer_tall_train_uniencdec\\n      * transformer_teeny\\n      * transformer_test\\n      * transformer_timeseries\\n      * transformer_timeseries_tpu\\n      * transformer_tiny\\n      * transformer_tiny_bs1\\n      * transformer_tiny_bs2\\n      * transformer_tiny_bs3\\n      * transformer_tiny_tpu\\n      * transformer_topk_16_packed\\n      * transformer_tpu\\n      * transformer_tpu_1b\\n      * transformer_tpu_bf16_activation\\n      * transformer_tpu_with_conv\\n      * transformer_wikitext103_l16k_memory_v0\\n      * transformer_wikitext103_l4k_memory_v0\\n      * transformer_wikitext103_l4k_v0\\n    universal:\\n      * universal_transformer_base\\n      * universal_transformer_base_fp16\\n      * universal_transformer_base_tpu\\n      * universal_transformer_big\\n      * universal_transformer_dwa_base\\n      * universal_transformer_gru_base\\n      * universal_transformer_highway_base\\n      * universal_transformer_lstm_base\\n      * universal_transformer_lstm_tall\\n      * universal_transformer_mix_after_ut_base\\n      * universal_transformer_mix_before_ut_base\\n      * universal_transformer_position_random_timing_tiny\\n      * universal_transformer_position_step_timing_tiny\\n      * universal_transformer_sepconv_base\\n      * universal_transformer_sepconv_big\\n      * universal_transformer_skip_base\\n      * universal_transformer_small\\n      * universal_transformer_small_dropconnect\\n      * universal_transformer_step_sinusoid_timing_tiny\\n      * universal_transformer_tall\\n      * universal_transformer_teeny\\n      * universal_transformer_tiny\\n    vqa:\\n      * vqa_attention_base\\n      * vqa_attention_drop01_dna\\n      * vqa_attention_feature_base\\n      * vqa_attention_feature_batch1024\\n      * vqa_attention_feature_batch1024_dnz\\n      * vqa_attention_feature_batch1024_dnz_l2\\n      * vqa_attention_feature_batch1024_dnz_noscaledp\\n      * vqa_attention_feature_batch1024_drop01\\n      * vqa_attention_feature_batch1024_drop01_dna\\n      * vqa_attention_feature_batch1024_drop01_dna_concat\\n      * vqa_attention_feature_batch1024_lstmlayernorm\\n      * vqa_attention_feature_batch1024_numglimps1\\n      * vqa_attention_feature_batch512\\n      * vqa_attention_feature_dna\\n      * vqa_attention_feature_dnz\\n      * vqa_attention_feature_dnz_l2\\n      * vqa_attention_feature_dnz_noscaledp\\n      * vqa_attention_feature_hidden1024\\n      * vqa_attention_feature_imagefeat1024\\n      * vqa_attention_feature_imagefeat512\\n      * vqa_attention_feature_initializer\\n      * vqa_attention_feature_lstmlayernorm\\n      * vqa_attention_feature_nonormalization\\n      * vqa_attention_feature_numglimps1\\n      * vqa_attention_numglimps1\\n      * vqa_recurrent_self_attention_base\\n      * vqa_recurrent_self_attention_big\\n      * vqa_recurrent_self_attention_big_l4\\n      * vqa_recurrent_self_attention_drop1\\n      * vqa_recurrent_self_attention_drop3\\n      * vqa_recurrent_self_attention_gru\\n      * vqa_recurrent_self_attention_highway\\n      * vqa_recurrent_self_attention_l4\\n      * vqa_recurrent_self_attention_l8\\n      * vqa_recurrent_self_attention_ls2\\n      * vqa_recurrent_self_attention_mix_before_ut\\n      * vqa_recurrent_self_attention_small\\n      * vqa_self_attention_base\\n      * vqa_self_attention_feature\\n      * vqa_self_attention_feature_batch1024\\n      * vqa_self_attention_feature_batch1024_big\\n      * vqa_self_attention_feature_batch1024_drop03\\n      * vqa_self_attention_feature_batch1024_exp\\n      * vqa_self_attention_feature_batch1024_hidden6\\n      * vqa_self_attention_feature_batch1024_hidden6_big\\n      * vqa_self_attention_feature_lr5\\n    wiki:\\n      * wiki_2x2_base\\n      * wiki_2x2_local\\n      * wiki_2x2_v1\\n    xception:\\n      * xception_base\\n      * xception_tiny\\n      * xception_tiny_tpu\\n    xmoe2:\\n      * xmoe2_dense\\n      * xmoe2_dense_0\\n      * xmoe2_dense_1\\n      * xmoe2_dense_2\\n      * xmoe2_dense_3\\n      * xmoe2_tiny\\n      * xmoe2_v1\\n      * xmoe2_v1_l4k\\n      * xmoe2_v1_l4k_compressed_c4\\n      * xmoe2_v1_l4k_compressed_c8\\n      * xmoe2_v1_l4k_global_only\\n      * xmoe2_v1_l4k_local_only\\n      * xmoe2_v1_x128\\n    xmoe:\\n      * xmoe_2d\\n      * xmoe_2d_c15\\n      * xmoe_2d_debug\\n      * xmoe_2d_x64\\n      * xmoe_dense_4k\\n      * xmoe_dense_64k\\n      * xmoe_dense_8k\\n      * xmoe_top_2\\n      * xmoe_top_2_c15\\n      * xmoe_tr_1d\\n      * xmoe_tr_2d\\n      * xmoe_tr_dense_2k\\n      * xmoe_tr_dense_32k'"
     ]
    }
   ],
   "source": [
    "visualizer = visualization.AttentionVisualizer(hparams_set, model_name, data_dir, problem_name, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph is finalized and cannot be modified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1411844d1dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'global_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sess = tf.train.MonitoredTrainingSession(\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_summaries_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2509\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m           shape=shape)\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m           self._initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1711\u001b[0;31m               initial_value, name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[1;32m   1712\u001b[0m           \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    289\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 290\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3586\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3588\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3589\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dave/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_check_not_finalized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \"\"\"\n\u001b[1;32m   3224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3225\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Graph is finalized and cannot be modified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Graph is finalized and cannot be modified."
     ]
    }
   ],
   "source": [
    "tf.Variable(0, dtype=tf.int64, trainable=False, name='global_step')\n",
    "\n",
    "sess = tf.train.MonitoredTrainingSession(\n",
    "    checkpoint_dir=CHECKPOINT,\n",
    "    save_summaries_secs=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1db937c00cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"I have two dogs.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vis_data_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualizer' is not defined"
     ]
    }
   ],
   "source": [
    "input_sentence = \"I have two dogs.\"\n",
    "output_string, inp_text, out_text, att_mats = visualizer.get_vis_data_from_string(sess, input_sentence)\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Visualizations\n",
    "- The layers drop down allow you to view the different Transformer layers, 0-indexed of course.\n",
    "  - Tip: The first layer, last layer and 2nd to last layer are usually the most interpretable.\n",
    "- The attention dropdown allows you to select different pairs of encoder-decoder attentions:\n",
    "  - All: Shows all types of attentions together. NOTE: There is no relation between heads of the same color - between the decoder self attention and decoder-encoder attention since they do not share parameters.\n",
    "  - Input - Input: Shows only the encoder self-attention.\n",
    "  - Input - Output: Shows the decoder’s attention on the encoder. NOTE: Every decoder layer attends to the final layer of encoder so the visualization will show the attention on the final encoder layer regardless of what layer is selected in the drop down.\n",
    "  - Output - Output: Shows only the decoder self-attention. NOTE: The visualization might be slightly misleading in the first layer since the text shown is the target of the decoder, the input to the decoder at layer 0 is this text with a GO symbol prepreded.\n",
    "- The colored squares represent the different attention heads.\n",
    "  - You can hide or show a given head by clicking on it’s color.\n",
    "  - Double clicking a color will hide all other colors, double clicking on a color when it’s the only head showing will show all the heads again.\n",
    "- You can hover over a word to see the individual attention weights for just that position.\n",
    "  - Hovering over the words on the left will show what that position attended to.\n",
    "  - Hovering over the words on the right will show what positions attended to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inp_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ca19c081baef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0matt_mats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inp_text' is not defined"
     ]
    }
   ],
   "source": [
    "attention.show(inp_text, out_text, *att_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
